# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cx1sRNdKOJ0mSIQGPNjh72J63SEhJdNs
"""

import os
import cv2
import matplotlib.pyplot as plt
import numpy as np
from sklearn.cluster import KMeans
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import roc_curve, auc
# Load your skin cancer image dataset (replace with your data loading logic)
images = []  # List to store loaded images
labels = []  # List to store corresponding labels (normal/cancerous)

data_directory = '/content/drive/My Drive/Skin_Data/Cancer/Training'  # Corrected path

# Load images and labels (ensure appropriate loading based on your dataset format)
for filename in os.listdir(data_directory):
    # Construct the full path to the file
    filepath = os.path.join(data_directory, filename)

    # Read the image using OpenCV
    image = cv2.imread(filepath)
    resized_image = cv2.resize(image, (28, 28))

    # Flatten the image (if needed)
    flattened_image = resized_image.flatten()

    # Append the flattened image to the list of images
    images.append(flattened_image)

    # Extract the label from the filename
    label_parts = filename.split('-')[:-1]  # Exclude the last part (image file extension)
    label = '-'.join(label_parts)
    labels.append(label)

# Convert lists to numpy arrays
images = np.array(images)
labels = np.array(labels)

# Split data into training and testing sets (80%/20%)
X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)

# Feature extraction using K-Means clustering (reduce dimensionality)
kmeans = KMeans(n_clusters=10, random_state=0)  # Adjust n_clusters as needed
kmeans.fit(X_train)
X_train_reduced = kmeans.transform(X_train)
X_test_reduced = kmeans.transform(X_test)
# K-Nearest Neighbors (KNN) classifier
knn_clf = KNeighborsClassifier(n_neighbors=5)  # Adjust n_neighbors as needed
knn_clf.fit(X_train_reduced, y_train)
knn_predictions = knn_clf.predict(X_test_reduced)
knn_accuracy = accuracy_score(y_test, knn_predictions)

print(f"KNN Accuracy: {knn_accuracy:.2f}")  # Print the accuracy
# Decision Tree classifier
tree_clf = DecisionTreeClassifier(random_state=42)
tree_clf.fit(X_train_reduced, y_train)
tree_predictions = tree_clf.predict(X_test_reduced)
tree_accuracy = accuracy_score(y_test, tree_predictions)
print(f"Decision Tree Accuracy: {tree_accuracy:.2f}")  # Print the accuracy

# Third classifier using K-Means clustering
kmeans_clf = KNeighborsClassifier(n_neighbors=5)  # Adjust parameters as needed
kmeans_clf.fit(X_train_reduced, y_train)
kmeans_predictions = kmeans_clf.predict(X_test_reduced)
kmeans_accuracy = accuracy_score(y_test, kmeans_predictions)

print(f"K-Means Classifier Accuracy: {kmeans_accuracy:.2f}")  # Print the accuracy

# Confusion Matrix for KNN Classifier
knn_conf_matrix = confusion_matrix(y_test, knn_predictions)
plt.figure(figsize=(8, 6))
plt.imshow(knn_conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix for KNN Classifier')
plt.colorbar()
tick_marks = np.arange(len(np.unique(labels)))
plt.xticks(tick_marks, np.unique(labels), rotation=45)
plt.yticks(tick_marks, np.unique(labels))
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()


# Precision-Recall Curve for Decision Tree Classifier
tree_precision = dict()
tree_recall = dict()
tree_thresholds = dict()
n_classes = len(np.unique(labels))
# Compute precision, recall, and thresholds for each class
for i in range(n_classes):
    tree_precision[i], tree_recall[i], tree_thresholds[i] = precision_recall_curve(y_test == i, tree_predictions == i)
    plt.plot(tree_recall[i], tree_precision[i], marker='.', label=f'Class {i}')

plt.title('Precision-Recall Curve for Decision Tree Classifier')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.grid(True)
plt.legend()
plt.show()
# ROC Curve for K-Means Classifier

# Compute ROC curve and ROC AUC for each class
kmeans_fpr = dict()
kmeans_tpr = dict()
kmeans_roc_auc = dict()
n_classes = len(np.unique(labels))
for i in range(n_classes):
    kmeans_fpr[i], kmeans_tpr[i], _ = roc_curve(y_test == i, kmeans_predictions == i)
    kmeans_roc_auc[i] = auc(kmeans_fpr[i], kmeans_tpr[i])
    plt.plot(kmeans_fpr[i], kmeans_tpr[i], lw=2, label=f'ROC curve (area = {kmeans_roc_auc[i]:.2f}) for Class {i}')

plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)
plt.title('ROC Curve for K-Means Classifier')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')
plt.show()

from google.colab import drive
drive.mount('/content/drive')